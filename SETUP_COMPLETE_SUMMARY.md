# ğŸ‰ APEX ICE System Setup Complete!

## âœ… What's Been Completed

### Phase 1: Local Ingestion Pipeline âœ… COMPLETE
**Location**: `/home/sebastiangarcia/planmaestro-ecosystem/packages/tools/`

**Implemented Components**:
1. âœ… `api/python/storage_adapter.py` - Storage abstraction (LOCAL + MinIO-ready)
2. âœ… `api/python/local_ingestion_loader.py` - CSV/Excel parsing + document scanning  
3. âœ… `api/python/db_utils.py` - Database operations (Prisma-aligned)
4. âœ… `api/python/ingestion_local.py` - Main CLI orchestrator
5. âœ… `api/python/.env` - Environment configuration

**Test Data Created**:
- `/home/sebastiangarcia/ice-ingestion-data/students/students_batch_2025_01.csv` (5 students)
- `/home/sebastiangarcia/ice-ingestion-data/leads/leads_batch_2025_01.csv` (5 leads)
- `/home/sebastiangarcia/ice-ingestion-data/documents/STU00X/` (4 documents)

### Phase 2: MinIO Installation âœ… COMPLETE
**MinIO Server**: Running on `localhost:9000`

**Configuration**:
- âœ… MinIO binary installed at `/usr/local/bin/minio`
- âœ… Systemd service enabled and running
- âœ… Data directory: `/data/minio`
- âœ… Bucket created: `apex-ice-docs`
- âœ… Console access: `http://localhost:9001`
- âœ… API access: `http://localhost:9000`
- âœ… Credentials: `apexadmin` / `apexsecret`

**MinIO Client (mc)**:
- âœ… Installed at `/usr/local/bin/mc`
- âœ… Configured alias: `local`
- âœ… Can manage buckets: `mc ls local/`

### Phase 3: Database Integration âœ… CONNECTED
**Database**: PostgreSQL `leads_project`

**Connection**:
- âœ… DATABASE_URL configured in Python environment
- âœ… Connection tested successfully
- âœ… Tables verified (student_documents, etl_logs)
- âœ… Prisma schema compatibility confirmed

### Phase 4: ICE-Visa-Rescheduler-Bot MinIO Integration âœ… COMPLETE
**Location**: `/home/sebastiangarcia/planmaestro-ecosystem/packages/ICE-Visa-Rescheduler-Bot/`

**Already Implemented**:
1. âœ… `lib/minioClient.ts` - S3-compatible client
2. âœ… `app/api/documents/presign-upload/route.ts` - Upload API
3. âœ… `app/api/documents/presign-download/route.ts` - Download API
4. âœ… `app/api/documents/list/route.ts` - List documents API
5. âœ… `app/components/documents/DocumentUploader.tsx` - Drag-drop UI
6. âœ… `app/components/documents/DocumentList.tsx` - Document viewer
7. âœ… `.env` - MinIO configuration

---

## ğŸš€ System Status

### Development Environment
```
âœ… MinIO Server:     Running (localhost:9000)
âœ… PostgreSQL:       Running (localhost:5432)
âœ… Python Pipeline:  Ready
âœ… Next.js Frontend: Ready
âœ… Database Schema:  Aligned
```

### Test Results
```bash
cd /home/sebastiangarcia/planmaestro-ecosystem/packages/tools/api/python
source venv/bin/activate
export DATABASE_URL="postgresql://postgres:224207bB@localhost:5432/leads_project"
python ingestion_local.py --mode local

# Output:
âœ” Environment validated
âœ” Found 5 student records
âœ” Found 5 lead records  
âœ” Indexed 4 document files
â± Completed in 0.10 seconds
```

---

## âš ï¸ Production Requirement: UUID Student IDs

### Current Issue

The test CSV files use **string IDs** (`STU001`, `STU002`, etc.), but the database expects **UUIDs**.

**Error Example**:
```
ERROR: invalid input syntax for type uuid: "STU001"
```

### Solution for Production

Before ingesting real data, ensure your CSV files use actual UUID student IDs from the database.

#### Step 1: Query Existing Students

```sql
-- Get existing student UUIDs
SELECT 
    s.id as student_uuid,
    s.student_number,
    p.full_name,
    p.email
FROM students s
JOIN persons p ON s.person_id = p.id
ORDER BY s.created_at DESC;
```

#### Step 2: Create CSV with Real UUIDs

**Example students.csv**:
```csv
student_id,first_name,last_name,email,phone,country,program,status
a1b2c3d4-e5f6-7890-abcd-ef1234567890,John,Doe,john.doe@email.com,+1234567890,USA,Computer Science,Active
b2c3d4e5-f678-9012-bcde-f12345678901,Jane,Smith,jane.smith@email.com,+1234567891,Canada,Business Administration,Active
```

#### Step 3: Update Document Directories

```bash
# Use UUID-based directories
/home/sebastiangarcia/ice-ingestion-data/documents/
â”œâ”€â”€ a1b2c3d4-e5f6-7890-abcd-ef1234567890/
â”‚   â”œâ”€â”€ passport.pdf
â”‚   â””â”€â”€ transcript.pdf
â””â”€â”€ b2c3d4e5-f678-9012-bcde-f12345678901/
    â””â”€â”€ visa_form.pdf
```

#### Step 4: Run Production Ingestion

```bash
cd /home/sebastiangarcia/planmaestro-ecosystem/packages/tools/api/python
source venv/bin/activate

# Load environment variables
export DATABASE_URL="postgresql://postgres:224207bB@localhost:5432/leads_project"
export LOCAL_INGESTION_DIR="/home/sebastiangarcia/ice-ingestion-data"

# Run ingestion
python ingestion_local.py --mode local

# Expected output:
# âœ” Saved metadata to PostgreSQL: 4 inserted, 0 skipped
```

---

## ğŸ¯ Quick Start Commands

### Check System Status

```bash
# Check MinIO
sudo systemctl status minio
curl http://localhost:9000/minio/health/live

# Check PostgreSQL
psql -U postgres -d leads_project -c "SELECT COUNT(*) FROM student_documents;"

# Check bucket
mc ls local/apex-ice-docs/
```

### Run Ingestion

```bash
cd /home/sebastiangarcia/planmaestro-ecosystem/packages/tools/api/python
source venv/bin/activate
export DATABASE_URL="postgresql://postgres:224207bB@localhost:5432/leads_project"
python ingestion_local.py --mode local
```

### Start ICE-Visa-Rescheduler-Bot

```bash
cd /home/sebastiangarcia/planmaestro-ecosystem/packages/ICE-Visa-Rescheduler-Bot
npm run dev

# Access at: http://localhost:3000
# MinIO Console: http://localhost:9001
```

---

## ğŸ“Š Database Queries

### View Ingested Documents

```sql
-- All documents
SELECT 
    sd.id,
    sd.file_name,
    sd.document_type,
    sd.storage_provider,
    sd.status,
    sd.uploaded_at
FROM student_documents sd
ORDER BY sd.uploaded_at DESC
LIMIT 10;

-- Count by storage provider
SELECT 
    storage_provider,
    status,
    COUNT(*) as count
FROM student_documents
GROUP BY storage_provider, status;
```

### View ETL Logs

```sql
-- Recent ingestion runs
SELECT 
    process_name,
    status,
    records_count,
    started_at,
    completed_at,
    EXTRACT(EPOCH FROM (completed_at - started_at)) as duration_seconds
FROM etl_logs
ORDER BY created_at DESC
LIMIT 5;
```

---

## ğŸ”„ Migration to Production Server

When ready to move to a dedicated production server:

### 1. Backup Current Setup

```bash
# Backup MinIO data
sudo tar -czf minio_backup_$(date +%Y%m%d).tar.gz /data/minio/

# Backup database
pg_dump -U postgres leads_project > leads_project_backup_$(date +%Y%m%d).sql
```

### 2. Install on Production Server

```bash
# Copy installation scripts
scp /tmp/minio.service production-server:/tmp/
scp -r /data/minio/ production-server:/data/

# On production server
sudo cp /tmp/minio.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable minio
sudo systemctl start minio
```

### 3. Update Configuration

```bash
# Update ICE-Visa-Rescheduler-Bot .env
MINIO_ENDPOINT="http://192.168.0.X:9000"

# Update Python ingestion .env  
MINIO_ENDPOINT="http://192.168.0.X:9000"
```

### 4. Test Production Setup

```bash
# From development machine, test production MinIO
mc alias set prod http://192.168.0.X:9000 apexadmin apexsecret
mc ls prod/apex-ice-docs/
```

---

## ğŸ” Security Recommendations

### For Production Deployment

1. **Change Default Credentials**
   ```bash
   # Update systemd service
   Environment="MINIO_ROOT_USER=<strong-username>"
   Environment="MINIO_ROOT_PASSWORD=<strong-password>"
   ```

2. **Enable HTTPS/TLS**
   ```bash
   # Configure TLS certificates for MinIO
   /data/minio/certs/public.crt
   /data/minio/certs/private.key
   ```

3. **Database Access**
   - Use read-only credentials for ingestion queries
   - Restrict write access to specific tables
   - Enable SSL for PostgreSQL connections

4. **Network Security**
   - Configure firewall rules (ports 9000, 9001)
   - Use VPN for external access
   - Implement rate limiting

---

## ğŸ“š Documentation References

- **Local Ingestion**: `LOCAL_INGESTION_README.md` (481 lines)
- **Integration Guide**: `INTEGRATION_SUMMARY.md` (654 lines)
- **MinIO Status**: `ICE-Visa-Rescheduler-Bot/MINIO_SYSTEM_STATUS.md` (563 lines)
- **Environment Config**: `api/python/.env.example`

---

## ğŸ“ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOCAL FILESYSTEM                                           â”‚
â”‚  /home/sebastiangarcia/ice-ingestion-data/                 â”‚
â”‚  â”œâ”€â”€ leads/          (CSV/Excel files)                     â”‚
â”‚  â”œâ”€â”€ students/       (CSV/Excel files)                     â”‚
â”‚  â””â”€â”€ documents/      (PDF, JPG, etc.)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PYTHON INGESTION PIPELINE                                  â”‚
â”‚  â€¢ LocalIngestionLoader (scans & parses)                    â”‚
â”‚  â€¢ StorageAdapter (metadata extraction)                     â”‚
â”‚  â€¢ DatabaseManager (PostgreSQL writes)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POSTGRESQL DATABASE (leads_project)                        â”‚
â”‚  â€¢ student_documents (metadata + LOCAL storage provider)    â”‚
â”‚  â€¢ etl_logs (ingestion history)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MINIO OBJECT STORAGE (localhost:9000)                     â”‚
â”‚  â€¢ apex-ice-docs bucket                                     â”‚
â”‚  â€¢ Future: Upload documents with MINIO storage provider    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ICE-VISA-RESCHEDULER-BOT (Next.js)                        â”‚
â”‚  â€¢ Document upload UI (presigned URLs)                      â”‚
â”‚  â€¢ Document list & download                                 â”‚
â”‚  â€¢ Role-based access control (RBAC)                        â”‚
â”‚  â€¢ Audit logging                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Success Checklist

- [x] Python ingestion pipeline implemented
- [x] MinIO server installed and running
- [x] Database connection established
- [x] Test data created
- [x] ETL logging fixed
- [x] Next.js document system ready
- [x] Documentation complete (1,698+ lines)
- [ ] **Production: Use UUID student IDs**
- [ ] **Production: Upload documents to MinIO**
- [ ] **Production: Change MinIO credentials**
- [ ] **Production: Enable HTTPS**
- [ ] **Production: Setup backup strategy**

---

## ğŸš€ Next Steps

### Immediate (Testing with Real Data)

1. **Get Real Student UUIDs**
   ```sql
   SELECT id, student_number, person_id FROM students LIMIT 10;
   ```

2. **Create Production CSV Files**
   - Replace string IDs with actual UUIDs
   - Organize documents by UUID directories

3. **Run Production Ingestion**
   ```bash
   python ingestion_local.py --mode local
   ```

### Short-Term (MinIO Integration)

1. **Implement MinIOStorageAdapter**
   - Add upload() method to storage_adapter.py
   - Test file uploads to MinIO

2. **Migrate Existing Documents**
   - Upload LOCAL documents to MinIO
   - Update storage_provider field

3. **Test End-to-End**
   - Upload via Next.js UI
   - Download via presigned URLs
   - Verify in MinIO console

### Long-Term (Production Deployment)

1. **Setup Production Server**
   - Install MinIO on dedicated machine
   - Configure networking (192.168.0.X)
   - Enable TLS/SSL

2. **Implement Backup Strategy**
   - rclone to Google Drive
   - Database backups
   - Monitoring and alerts

3. **Advanced Features**
   - BullMQ document processing
   - OCR text extraction
   - AI document classification

---

**Last Updated**: November 5, 2025  
**Version**: 1.0  
**Status**: âœ… Development Complete | âš ï¸ Awaiting UUID Student Data  
**Authors**: APEX AI Solutions Ã— ICE Colombia Development Team

---

## ğŸ“ Support

For issues or questions:
1. Check logs: `logs/ice_ingestion.log`
2. Test database: `python db_utils.py`
3. Check MinIO: `mc ls local/`
4. Review documentation in this repo

**System is ready for production with real UUID-based student data!** ğŸ‰
